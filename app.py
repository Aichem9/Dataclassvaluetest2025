import os
import io
import re
import json
import base64
import pandas as pd
import streamlit as st

# ---- Optional LLM ----
OPENAI_AVAILABLE = False
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except Exception:
    pass

# ---- File parsers ----
from typing import List, Tuple

def read_pdf(file) -> str:
    try:
        from pypdf import PdfReader
        reader = PdfReader(file)
        return "\n".join([p.extract_text() or "" for p in reader.pages])
    except Exception:
        return ""

def read_docx(file) -> str:
    try:
        import docx
        doc = docx.Document(file)
        return "\n".join([p.text for p in doc.paragraphs])
    except Exception:
        return ""

def read_txt(file) -> str:
    try:
        return file.read().decode("utf-8", errors="ignore")
    except Exception:
        try:
            return file.read().decode("cp949", errors="ignore")
        except Exception:
            return ""

def extract_text(uploaded_files) -> str:
    texts = []
    for f in uploaded_files:
        name = f.name.lower()
        if name.endswith(".pdf"):
            texts.append(read_pdf(f))
        elif name.endswith(".docx"):
            texts.append(read_docx(f))
        elif name.endswith(".txt"):
            texts.append(read_txt(f))
        else:
            texts.append("")
    return "\n\n".join(texts).strip()

# ---- Framework (ìš”ì•½ ë²„ì „) ----
FRAMEWORK = {
    "ë°ì´í„° ì¸ì‹ ë° ì´í•´": [
        "ë°ì´í„° ê°œë…/ì •ì˜ ì´í•´", "ì •í˜•/ë¹„ì •í˜•Â·ì§ˆì /ì–‘ì  êµ¬ë¶„", "ë°ì´í„° ìƒì„±Â·ìˆ˜ì§‘ ë§¥ë½ ì´í•´",
        "ì¼ìƒ ì† ë°ì´í„° ì¸ì‹", "ë°ì´í„°-ì •ë³´-ì§€ì‹ ê´€ê³„"
    ],
    "ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬": [
        "ì í•©í•œ ìˆ˜ì§‘ ë°©ë²•(ê´€ì°°Â·ì¸¡ì •Â·ì„¤ë¬¸ ë“±)", "ë°ì´í„° êµ¬ì¡°í™”Â·ì •ì œÂ·í’ˆì§ˆ(ì •í™•ì„±Â·ì™„ì „ì„±Â·ì‹ ë¢°ì„±)",
        "ì €ì¥Â·ê´€ë¦¬Â·ê³µìœ  ì ˆì°¨", "2ì°¨/ê³µê³µë°ì´í„° í™œìš©"
    ],
    "ë°ì´í„° ë¶„ì„ ë° í•´ì„": [
        "ê¸°ìˆ í†µê³„/íŒ¨í„´/ì´ìƒì¹˜", "ê´€ê³„ ë¶„ì„(ìƒê´€Â·ì¸ê³¼)", "í†µê³„ì  ì¶”ë¡ Â·ê°€ì„¤ê²€ì¦",
        "ë„êµ¬ í™œìš©(ìŠ¤í”„ë ˆë“œì‹œíŠ¸Â·ë¶„ì„íˆ´)", "ê·¼ê±° ê¸°ë°˜ í•´ì„"
    ],
    "ë°ì´í„° í™œìš© ë° í‘œí˜„": [
        "ëª©ì  ë§ëŠ” ì‹œê°í™” ì„ íƒ", "ìŠ¤í† ë¦¬í…”ë§Â·ë…¼ì¦", "ì²­ì¤‘ ë§ì¶¤ í‘œí˜„",
        "ë°ì´í„° ê¸°ë°˜ ì˜ì‚¬ê²°ì •/ë¬¸ì œ í•´ê²°"
    ],
    "ë°ì´í„° ìœ¤ë¦¬ ë° ë¹„íŒì  ì‚¬ê³ ": [
        "ê°œì¸ì •ë³´Â·í”„ë¼ì´ë²„ì‹œ", "ì¶œì²˜Â·ì‹ ë¢°ì„± ê²€ì¦", "í¸í–¥Â·ì™œê³¡Â·í—ˆìœ„ì •ë³´ íŒë³„",
        "ì•Œê³ ë¦¬ì¦˜ í¸í–¥/ì‚¬íšŒì  ì˜í–¥Â·ì±…ì„"
    ],
}

RUBRIC_SCALE = ["ë³´ì™„ í•„ìš” (1ì )", "ë³´í†µ (2ì )", "ìš°ìˆ˜ (3ì )"]

# ---- Keyword heuristics (API ì—†ì„ ë•Œ) ----
HEURISTICS = {
    "ë°ì´í„° ì¸ì‹ ë° ì´í•´": [
        r"ë°ì´í„°ì˜ ê°œë…|ì •ì˜|ë©”íƒ€ë°ì´í„°|ì •í˜•|ë¹„ì •í˜•|ì§ˆì |ì–‘ì |ë°ì´í„° ìƒíƒœê³„|ë°ì´í„° ê³¼í•™|ë°ì´í„° ê²½ì œ"
    ],
    "ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬": [
        r"ê´€ì°°|ì¸¡ì •|ì„¤ë¬¸|í‘œë³¸|ì •ì œ|í’ˆì§ˆ|ì‹ ë¢°ì„±|ì •í™•ì„±|ì €ì¥|ê´€ë¦¬|ê³µìœ |ë³´ì•ˆ|ê³µê³µ ë°ì´í„°|ë°ì´í„°ë² ì´ìŠ¤|í¬ë¡¤ë§"
    ],
    "ë°ì´í„° ë¶„ì„ ë° í•´ì„": [
        r"í‰ê· |ì¤‘ì•™ê°’|ìµœë¹ˆê°’|ë¶„ì‚°|í‘œì¤€í¸ì°¨|ìƒê´€|íšŒê·€|ê°€ì„¤|ì¶”ë¡ |ëª¨ë¸|ì˜ˆì¸¡|ë¶„ì„ ë„êµ¬|ìŠ¤í”„ë ˆë“œì‹œíŠ¸"
    ],
    "ë°ì´í„° í™œìš© ë° í‘œí˜„": [
        r"ì‹œê°í™”|ê·¸ë˜í”„|ì°¨íŠ¸|ì¸í¬ê·¸ë˜í”½|ëŒ€ì‹œë³´ë“œ|ìŠ¤í† ë¦¬í…”ë§|ë°œí‘œ|ë³´ê³ ì„œ|ì˜ì‚¬ê²°ì •|ì •ì±…"
    ],
    "ë°ì´í„° ìœ¤ë¦¬ ë° ë¹„íŒì  ì‚¬ê³ ": [
        r"ê°œì¸ì •ë³´|í”„ë¼ì´ë²„ì‹œ|ì¶œì²˜|ì‹ ë¢°ì„±|í¸í–¥|ì™œê³¡|í—ˆìœ„ ì •ë³´|ê³µì •ì„±|ê±°ë²„ë„ŒìŠ¤|ìœ¤ë¦¬|ì±…ì„"
    ],
}

def heuristic_score(text: str, pattern: str) -> int:
    if not text:
        return 1
    hits = len(re.findall(pattern, text, flags=re.IGNORECASE))
    if hits >= 6:
        return 3
    elif hits >= 2:
        return 2
    return 1

def run_heuristic_eval(text: str) -> Tuple[pd.DataFrame, str]:
    rows = []
    recs = []
    for cat, patterns in HEURISTICS.items():
        score = max(heuristic_score(text, p) for p in patterns)
        rows.append([cat, score])
        # ê°„ë‹¨ ì¶”ì²œ
        if score < 3:
            if cat == "ë°ì´í„° ìˆ˜ì§‘ ë° ê´€ë¦¬":
                recs.append("ë°ì´í„° í’ˆì§ˆ(ì •í™•ì„±Â·ì™„ì „ì„±Â·ì‹ ë¢°ì„±)ê³¼ ì €ì¥Â·ë³´í˜¸ ì ˆì°¨ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.")
            elif cat == "ë°ì´í„° ë¶„ì„ ë° í•´ì„":
                recs.append("ìš”ì•½ì„ ë„˜ì–´ ìƒê´€Â·ê°€ì„¤ê²€ì¦ ë“± í•´ì„ ê·¼ê±°ë¥¼ í¬í•¨í•˜ì„¸ìš”.")
            elif cat == "ë°ì´í„° í™œìš© ë° í‘œí˜„":
                recs.append("ì‹œê°í™” ê²°ê³¼ë¥¼ ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œ ì—°ê²°í•˜ê³  ì˜ì‚¬ê²°ì •ì„ ëª…ì‹œí•˜ì„¸ìš”.")
            elif cat == "ë°ì´í„° ìœ¤ë¦¬ ë° ë¹„íŒì  ì‚¬ê³ ":
                recs.append("ê°œì¸ì •ë³´Â·í¸í–¥Â·ì¶œì²˜ê²€ì¦ ë“± ìœ¤ë¦¬ì  ì„±ì°° í™œë™ì„ ì„¤ê³„í•˜ì„¸ìš”.")
            elif cat == "ë°ì´í„° ì¸ì‹ ë° ì´í•´":
                recs.append("ì •í˜•/ë¹„ì •í˜•Â·ì§ˆì /ì–‘ì  êµ¬ë¶„ê³¼ ë°ì´í„° ìƒíƒœê³„ë¥¼ ë„ì‹í™”í•˜ì„¸ìš”.")
    df = pd.DataFrame(rows, columns=["ë²”ì£¼", "ì ìˆ˜"]).set_index("ë²”ì£¼")
    summary = "\n".join(sorted(set(recs)))
    return df, summary

# ---- LLM evaluation ----
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ì˜ êµì‚¬ ì—°ìˆ˜ìš© ìë£Œë¥¼ í‰ê°€í•˜ëŠ” êµìœ¡ê³¼ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì…ë ¥ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë°ì´í„°ë¦¬í„°ëŸ¬ì‹œ 5ëŒ€ ë²”ì£¼(ì¸ì‹, ìˆ˜ì§‘, ë¶„ì„, í™œìš©, ìœ¤ë¦¬)ì— ëŒ€í•´
ê° ë²”ì£¼ë¥¼ 1~3ì (1=ë³´ì™„ í•„ìš”, 2=ë³´í†µ, 3=ìš°ìˆ˜)ìœ¼ë¡œ ì±„ì í•˜ê³ , ì±„ì  ê·¼ê±° í•µì‹¬ë¬¸ì¥/ê·¼ê±° í‚¤ì›Œë“œë¥¼ ì œì‹œí•œ ë’¤,
ì¢…í•© ë³´ì™„ ì‚¬í•­ì„ 5ê°œ ì´ë‚´ë¡œ í•œêµ­ì–´ë¡œ ê°„ê²°íˆ ì œì•ˆí•˜ì„¸ìš”.
ê²°ê³¼ëŠ” JSONìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”: 
{"rubric": [{"category": "...", "score": 1|2|3, "evidence": ["...","..."]}, ...],
 "recommendations": ["...","..."]}"""

def run_llm_eval(text: str, api_key: str) -> Tuple[pd.DataFrame, str]:
    client = OpenAI(api_key=api_key)
    msg = [
        {"role":"system","content": SYSTEM_PROMPT},
        {"role":"user","content": text[:15000]} # í† í° ê³¼ë‹¤ ë°©ì§€
    ]
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=msg,
        temperature=0.2
    )
    raw = resp.choices[0].message.content.strip()
    try:
        data = json.loads(raw)
    except Exception:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ëŒ€ì²´
        return run_heuristic_eval(text)

    rows = []
    for item in data.get("rubric", []):
        rows.append([item.get("category",""), int(item.get("score",2)), " / ".join(item.get("evidence", [])[:3])])
    if not rows:
        return run_heuristic_eval(text)

    df = pd.DataFrame(rows, columns=["ë²”ì£¼", "ì ìˆ˜", "ê·¼ê±°"]).set_index("ë²”ì£¼")
    summary = "\n".join(data.get("recommendations", []))
    return df, summary

# ---- Helpers ----
def df_to_csv_download(df: pd.DataFrame, filename: str = "rubric.csv"):
    csv = df.to_csv().encode("utf-8-sig")
    st.download_button("â¬‡ï¸ ë£¨ë¸Œë¦­(CSV) ë‹¤ìš´ë¡œë“œ", data=csv, file_name=filename, mime="text/csv")

def text_download(content: str, filename: str = "report.md"):
    b = content.encode("utf-8")
    st.download_button("â¬‡ï¸ ì¢…í•© ë³´ì™„ ì‚¬í•­(MD) ë‹¤ìš´ë¡œë“œ", data=b, file_name=filename, mime="text/markdown")

def make_markdown_report(df: pd.DataFrame, recs: str, source_info: str) -> str:
    total = int(df["ì ìˆ˜"].sum())
    md = [f"# ë°ì´í„°ë¦¬í„°ëŸ¬ì‹œ ìˆ˜ì—… ë¶„ì„ ë³´ê³ ì„œ",
          "",
          f"- ì´ì : **{total} / 15**",
          "",
          "## ë£¨ë¸Œë¦­ ê²°ê³¼",
          df.to_markdown(),
          "",
          "## ì¢…í•© ë³´ì™„ ì‚¬í•­",
          recs or "- (ì—†ìŒ)",
          "",
          "## ë¶„ì„ ì •ë³´",
          source_info]
    return "\n".join(md)

# ---- UI ----
st.set_page_config(page_title="ë°ì´í„°ë¦¬í„°ëŸ¬ì‹œ ìˆ˜ì—… ë¶„ì„ ë„ìš°ë¯¸", layout="wide")
st.title("ğŸ§ª ë°ì´í„°ë¦¬í„°ëŸ¬ì‹œ ìˆ˜ì—… ë¶„ì„ ë„ìš°ë¯¸ (Streamlit)")

with st.sidebar:
    st.header("ì„¤ì •")
    st.markdown("- íŒŒì¼ ì—…ë¡œë“œ í›„ **ë¶„ì„ ì‹œì‘**ì„ í´ë¦­í•˜ì„¸ìš”.\n- OpenAI í‚¤ê°€ ìˆìœ¼ë©´ LLM ê¸°ë°˜ ì •ë°€ í‰ê°€ê°€ ìˆ˜í–‰ë©ë‹ˆë‹¤.")
    api_key = st.text_input("OpenAI API Key (ì„ íƒ)", type="password", help="ì…ë ¥ ì‹œ LLM í‰ê°€ ì‚¬ìš©, ë¯¸ì…ë ¥ ì‹œ íœ´ë¦¬ìŠ¤í‹± í‰ê°€")
    st.markdown("---")
    st.markdown("**ì§€ì› íŒŒì¼**: PDF, DOCX, TXT")

uploaded = st.file_uploader("ìˆ˜ì—…ìë£Œ ì—…ë¡œë“œ (ì—¬ëŸ¬ ê°œ ê°€ëŠ¥)", type=["pdf","docx","txt"], accept_multiple_files=True)

if uploaded:
    with st.expander("ì—…ë¡œë“œ íŒŒì¼ ëª©ë¡", expanded=False):
        for f in uploaded:
            st.write("â€¢", f.name)

start = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", use_container_width=True)

if start:
    text = extract_text(uploaded) if uploaded else ""
    if not text:
        st.error("í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. PDF ìŠ¤ìº”ë³¸ì´ë¼ë©´ OCR í›„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        st.stop()

    # í‘œì‹œìš© ì†ŒìŠ¤ ì •ë³´
    src_names = ", ".join([f.name for f in uploaded]) if uploaded else "ì…ë ¥ í…ìŠ¤íŠ¸"
    st.info(f"ë¶„ì„ ëŒ€ìƒ: {src_names}")

    # í‰ê°€ ì‹¤í–‰
    if api_key and OPENAI_AVAILABLE:
        df, recs = run_llm_eval(text, api_key)
        st.success("LLM ê¸°ë°˜ ì •ë°€ í‰ê°€ ì™„ë£Œ")
    else:
        df, recs = run_heuristic_eval(text)
        st.warning("OpenAI í‚¤ ë¯¸ì…ë ¥ â†’ íœ´ë¦¬ìŠ¤í‹± í‰ê°€ ìˆ˜í–‰")

    # ì ìˆ˜ í‘œ
    left, right = st.columns([2,1])
    with left:
        st.subheader("ğŸ“Š ë£¨ë¸Œë¦­")
        st.dataframe(df, use_container_width=True)
    with right:
        st.metric(label="ì´ì  (15ì  ë§Œì )", value=int(df["ì ìˆ˜"].sum()))

    # ì„¸ë¶€ ê·¼ê±° ë³´ê¸° (LLM ëª¨ë“œì¼ ë•Œ ê·¼ê±° ì»¬ëŸ¼ ì¡´ì¬)
    if "ê·¼ê±°" in df.columns:
        with st.expander("ê·¼ê±°/í‚¤ì›Œë“œ ë³´ê¸°", expanded=False):
            st.table(df[["ê·¼ê±°"]])

    st.subheader("ğŸ§­ ì¢…í•© ë³´ì™„ ì‚¬í•­")
    st.write(recs if recs else "- (ì—†ìŒ)")

    # ë‹¤ìš´ë¡œë“œ
    md_report = make_markdown_report(df, recs, f"ì†ŒìŠ¤: {src_names}")
    df_to_csv_download(df)
    text_download(md_report, filename="ìˆ˜ì—…ë¶„ì„_ë³´ê³ ì„œ.md")

    st.download_button(
        "â¬‡ï¸ ì „ì²´ ë³´ê³ ì„œ(Markdown) ë‹¤ìš´ë¡œë“œ",
        data=md_report.encode("utf-8"),
        file_name="ë°ì´í„°ë¦¬í„°ëŸ¬ì‹œ_ë¶„ì„_ë³´ê³ ì„œ.md",
        mime="text/markdown"
    )

# í•˜ë‹¨ ì •ë³´
st.markdown("---")
st.caption("â€» ë³¸ ë„êµ¬ëŠ” êµìœ¡ì  ì°¸ê³ ìš©ì…ë‹ˆë‹¤. ê°œì¸ì •ë³´Â·ì €ì‘ê¶ŒÂ·ìœ¤ë¦¬ ê°€ì´ë“œë¥¼ ì¤€ìˆ˜í•˜ì„¸ìš”.")
